--- 
title: "NIMBLE User Manual"
author: "NIMBLE Development Team"
date: "Version 0.6-11"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook."
---
Problem is these next items appear after TOC

[https://R-nimble.org](https://R-nimble.org)

[https://github.com/nimble-dev/nimble-docs](https://github.com/nimble-dev/nimble-docs)
<!---
, 'chapter_MCMC.Rmd', 'chapter_OtherAlgorithms.Rmd', 'chapter_Spatial.Rmd', 'chapter_ProgrammingOverview.Rmd', 'chapter_RCfunctions.Rmd', 'chapter_UserDefined.Rmd', 'chapter_UsingModels.Rmd', 'chapter_DataStructures.Rmd', 'chapter_WritingNimbleFunctions.Rmd']
-->

```{r echo=FALSE, include=FALSE}
library(knitr)
library(nimble)
library(methods)
opts_chunk$set(eval = TRUE)
runMCEMs <- FALSE
#version="0.6-11"
```


<!--chapter:end:index.Rmd-->

# (PART) Part I {Introduction} 

<!--chapter:end:part1.md-->

<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->


# Welcome to NIMBLE {#sec:welcome-nimble}

NIMBLE is a system for building and sharing analysis methods for
statistical models from R, especially for hierarchical models and
computationally-intensive methods.  While NIMBLE is embedded in R, it
goes beyond R by supporting separate programming of models and
algorithms along with compilation for fast execution.  

As of version `r version`, NIMBLE has been around for a while and is reasonably
stable, but we have a lot of plans to expand and improve it.  The
algorithm library provides MCMC with a lot of user control and ability
to write new samplers easily.  Other algorithms include particle
filtering (sequential Monte Carlo) and Monte Carlo Expectation
Maximization (MCEM).  

But NIMBLE is about much more than providing an algorithm library.  It
provides a language for writing model-generic algorithms.  We hope you
will program in NIMBLE and make an R package providing your method.
Of course, NIMBLE is open source, so we also hope you'll contribute to
its development.

Please join the mailing lists
(see [R-nimble.org/more/issues-and-groups](https://r-nimble.org/more/issues-and-groups)) and help improve NIMBLE by
telling us what you want to do with it, what you like, and what could
be better.  We have a lot of ideas for how to improve it, but we want
your help and ideas too.  You can also follow and contribute to
developer discussions on the
[wiki of our GitHub
  repository](https://github.com/nimble-dev/nimble/wiki).

If you use NIMBLE in your work, please cite us, as this helps justify past and future funding
for the development of NIMBLE. For more information, please call `citation('nimble')` in R.

## What does NIMBLE do? {#sec:what-is-nimble}

NIMBLE makes it easier to program statistical algorithms that will run
efficiently and work on many different models from R.

You can think of NIMBLE as comprising four pieces:


  * A system for writing statistical models flexibly, which is an
  extension of the BUGS language^[See Chapter
    \@ref(cha:writing-models) for information about NIMBLE's version of
    BUGS.].
  * A library of algorithms such as MCMC.
  * A language, called NIMBLE, embedded within and similar in style
  to R, for writing algorithms that operate on models written in BUGS.
  *  A compiler that generates C++ for your models and algorithms,
  compiles that C++, and lets you use it seamlessly from R without
  knowing anything about C++.


NIMBLE stands for Numerical Inference for statistical Models for
Bayesian and Likelihood Estimation.  

Although NIMBLE was motivated by algorithms for hierarchical
statistical models, it's useful for other goals too.  You could use it
for simpler models.  And since NIMBLE can automatically compile R-like
functions into C++ that use the Eigen library for fast linear algebra,
you can use it to program fast numerical functions without any model
involved^[The packages [Rcpp](http://www.rcpp.org/) and
  RcppEigen provide different ways of connecting C++, the Eigen
  library and R.  In those packages you program directly in C++, while
  in NIMBLE you program in R in a nimbleFunction and the NIMBLE compiler
  turns it into C++.]

One of the beauties of R is that many of the high-level analysis
functions are themselves written in R, so it is easy to see their code and modify
them.  The same is true for NIMBLE: the algorithms are themselves
written in the NIMBLE language.

## How to use this manual

We suggest everyone start with the Lightning Introduction in Chapter \@ref(cha:intro).

Then, if you want to jump into using NIMBLE's algorithms without learning
about NIMBLE's programming system, go to Part \@ref(part:models) to
learn how to build your model and Part \@ref(part:algorithms) to learn
how to apply NIMBLE's built-in algorithms to your model.

If you want to learn about NIMBLE programming (nimbleFunctions), go to Part
\@ref(part:programming). This teaches how to program user-defined
function or distributions to use in BUGS code, compile your R code for
faster operations, and write algorithms with NIMBLE. These algorithms
could be specific algorithms for your particular model (such as a
user-defined MCMC sampler for a parameter in your model) or general
algorithms you can distribute to others. In fact the algorithms
provided as part of NIMBLE and described in Part \@ref(part:algorithms)
are written as nimbleFunctions.

<!--chapter:end:chapter_WelcomeToNimble.Rmd-->

<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->



```{r, chunk-LIinit, echo = FALSE}
## source the code
read_chunk(file.path('chunks', 'introExample_chunks.R'))  # one can put code chunks here if one wants
``` 


# Lightning introduction {#cha:intro}

## A brief example {#sec:brief-example}

Here we'll give a simple example of building a model and running some algorithms on the model, as well as creating our own user-specified algorithm. The goal is to give you a sense for what one can do in the system. Later sections will provide more detail.

We'll use the *pump* model example from BUGS^[The data set
  describes failure rates of some pumps.].  We could load the model
from the standard BUGS example file formats (Section \@ref(sec:readBUGSmodel)), but instead we'll show
how to enter it directly in R.

In this 'lightning introduction' we will:


  * Create the model for the pump example.
  * Compile the model.
  * Create a basic MCMC configuration for the pump model.
  * Compile and run the MCMC
  * Customize the MCMC configuration and compile and run that.
  * Create, compile and run a Monte Carlo Expectation Maximization (MCEM)
  algorithm, which illustrates some of the flexibility NIMBLE
  provides to combine R and NIMBLE.
  * Write a short `nimbleFunction` to generate simulations from
  designated nodes of any  model.



## Creating a model {#sec:creating-model}
First we define the model code, its constants, data, and initial
values for MCMC.

```{r, inputPump}
``` 

Here `x[i]` is the number of failures recorded during a time
duration of length `t[i]` for the `i`$^{th}$ pump.
`theta[i]` is a failure rate, and the goal is estimate parameters
`alpha` and `beta`.  Now let's create the model and look at some of its nodes.

```{r, explorePump}
``` 


Notice that in the list of nodes, NIMBLE has introduced a new node,
`lifted_d1_over_beta`. We call this a 'lifted' node. Like R,
NIMBLE allows alternative parameterizations, such as the scale or rate
parameterization of the gamma distribution. Choice of parameterization
can generate a lifted node, as can using a link function or a
distribution argument that is an expression. It's helpful to know why
they exist, but you shouldn't need to worry about them.

Thanks to the plotting capabilities of the `igraph` package that
NIMBLE uses to represent the directed acyclic graph, we can plot the
model  (Figure 2.1).

```{r, plotPump, fig.cap="Directed Acyclic Graph plot of the pump model, thanks to the igraph package"}
``` 

You are in control of the model.  By default, `nimbleModel` does
its best to initialize a model, but let's say you want to
re-initialize `theta`.  To simulate from the prior for `theta` (overwriting the
initial values previously in the model) we first need to be sure the
parent nodes of all `theta[i]` nodes are fully initialized, including any non-stochastic nodes such
as lifted nodes.  We then use the `simulate` function to simulate
from the distribution for `theta`.  Finally we use the
`calculate` function to 
calculate the dependencies of `theta`, namely `lambda` and the
log probabilities of `x` to ensure all parts of the
model are up to date.  First we show how
to use the model's `getDependencies` method to query information
about its graph.
<!---  TODO: the logic here is a bit weird - we say we want to know all parents of theta are initialized by our code actually finds dependencies of alpha+beta not parents of theta -->
```{r, manipPump}
"
``` 

Notice that the first `getDependencies` call returned dependencies
from `alpha` and `beta` down to the next stochastic nodes in the
model.  The second call requested only deterministic dependencies.
The call to `pump$simulate("theta")`
expands `"theta"` to include all nodes in `theta`.  After
simulating into `theta`, we can see that `lambda` and the log
probabilities of `x` still reflect the old values of `theta`, so
we `calculate` them and then see that they have been updated.

## Compiling the model {#sec:compiling-model}

Next we compile the model, which means generating C++ code, compiling
that code, and loading it back into R with an object that can be used just
like the uncompiled model. The values in the compiled model will be
initialized from those of the original model in R, but
the original and compiled models are distinct objects so any
subsequent changes in one will not be reflected in the other.

```{r, compilePump}
``` 

Note that the compiled model is used when running any NIMBLE algorithms via C++, so the model needs to be compiled before (or at the same time as) any compilation of algorithms, such as the compilation of the MCMC done in the next section.

## One-line invocation of MCMC {#sec:intro-runMCMC}

The most direct approach to invoking NIMBLE's MCMC engine is using the
`nimbleMCMC` function.  This function would generally take the code,
data, constants, and initial values as input, but it can also accept the (compiled or uncompiled)
model object as an argument. It provides a variety of options for executing and
controlling multiple chains of NIMBLE's default MCMC algorithm, and
returning posterior samples, posterior summary statistics,
and/or WAIC values.

For example, to execute two MCMC chains of 10,000 samples each, and
return samples, summary statistics, and WAIC values:

```{r, nimbleMCMCpump}
``` 

See Section \@ref(sec:nimbleMCMC) or `help(nimbleMCMC)` for more
details about using `nimbleMCMC`.


## Creating, compiling and running a basic MCMC configuration {#sec:creating-mcmc}
  
At this point we have initial values for all of the nodes in the model,
and we have both the original and compiled versions of the model. As a first algorithm
to try on our model, let's use NIMBLE's default MCMC. Note that conjugate relationships are detected for all nodes except for
`alpha`, on which the default sampler is a random walk Metropolis sampler.
<!--- ^[We haven't set up conjugate relationships for an -->%  exponential yet.]
<!---  footnote is true but not relevant as there is not a conj relationship for alpha in a gamma-distributed dependency -->
```{r, mcmcPump, fig.height=2.5}
``` 

Notice the posterior correlation between `alpha` and `beta`.
A measure of the mixing for each is the 
autocorrelation for each parameter, shown by the `acf` plots. 

## Customizing the MCMC {#sec:customizing-mcmc}

Let's add an adaptive
block sampler on `alpha` and `beta` jointly and see if that
improves the mixing. 

```{r, mcmcPump2, fig.height=2.5}
``` 

We can see that the block sampler has decreased the 
autocorrelation for both `alpha` and `beta`.  Of course these
are just short runs, and what we are really interested in is the
effective sample size of the MCMC per computation time, but that's not
the point of this example.

Once you learn the MCMC system, you can write your own samplers and
include them.  The entire system is written in nimbleFunctions.

## Running MCEM {#sec:running-mcem}

NIMBLE is a system for working with algorithms, not just an MCMC engine. So let's try maximizing the marginal likelihood for `alpha` and `beta` using Monte Carlo Expectation Maximization^[Note that for this model, one could analytically integrate over `theta` and then numerically maximize the resulting marginal likelihood.]. 

```{r, mcemPump, eval = runMCEMs, echo = runMCEMs}
``` 
```{r, dont-run-mcemPump, eval = !runMCEMs, echo = !runMCEMs}
``` 

Both estimates are within 0.01 of the values reported by
[@George_Makov_Smith_1993]^[Table 2 of the paper accidentally swapped the two estimates.]. %^[George, E.I., Makov, U.E. \& Smith,
<!---   A.F.M. 1993. Conjugate likelihood --> % distributions. *Scand. J. Statist.* \textbf{20]:147-156.
<!---  Their numbers were accidentally swapped in Table 2.}.   -->Some discrepancy is to be expected since it is a Monte Carlo algorithm.

## Creating your own functions {#sec:creating-your-own}



Now let's see an example of writing our own algorithm and using it on
the model. We'll do something simple: simulating multiple values for a
designated set of nodes and calculating every part of the model that
depends on them. More details on programming in NIMBLE are in Part \@ref(part:programming).

Here is our *nimbleFunction*:
```{r, nfPump}
``` 

Here are a few things to notice about the nimbleFunction.

  * The `setup` function is written in R.  It creates relevant
  information specific to our model for use in the run-time code.  
  * The `setup` code creates a *modelValues* object to hold multiple sets of
  values for variables  in the model provided.
  * The `run` function is written in NIMBLE.  It carries out the
  calculations using the information determined once for each set of
  `model` and `nodes` arguments by the setup
  code. The run-time code is what will be compiled.
  * The `run` code requires type information about the argument
  `n`.  In this case it is a scalar integer.  
  * The for-loop looks just like R, but only sequential integer
  iteration is allowed.
  * The functions `calculate` and `simulate`, which were
  introduced above in R, can be used in NIMBLE.
  * The special function `copy` is used here to record values
  from the model into the modelValues object.  
  * Multiple instances, or 'specializations', can be made by
  calling `simNodesMany` with different arguments.  Above, `simNodesTheta1to5` has
  been made by calling `simNodesMany` with the `pump` model and
  nodes `"theta[1:5]"` as inputs to
  the `setup` function, while `simNodesTheta6to10` differs by
  providing `"theta[6:10]"` as an argument.  The returned objects
  are objects of a uniquely
  generated R reference class with fields (member data) for the results of the
  `setup` code and a `run` method (member function). 
<!---  Arbitrary other methods can be provided with a `methods` argument, following the syntax of R's `setRefClass` function. -->  % NOTE: CJP removed previous sentence as I think it is too involved for the lightning intro - CJP


By the way, `simNodesMany` is very similar to a standard
`nimbleFunction` provided with nimble, `simNodesMV`.

Now let's execute this nimbleFunction in R, before compiling it.

```{r, runPumpSimsR}
``` 

In this code we have initialized the values of `alpha` and `beta`
to their MLE and then recorded the `theta` values to use below.  Then we
have requested 10 simulations from
`simNodesTheta1to5`.  Shown are the first two simulation results
for `theta` and the log probabilities of `x`.  Notice that
`theta[6:10]` and the corresponding log probabilities for `x[6:10]` are unchanged because the nodes being simulated are only
`theta[1:5]`.  In R, this function runs slowly.

Finally, let's compile the function and run that version.

```{r, runPumpSimsC}
``` 

Given the same initial values and the same random number generator
seed, we got identical results for `theta[1:5]` and their dependencies, but it happened much faster.


<!--chapter:end:chapter_LightningIntroduction.Rmd-->

<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->


# More introduction

Now that we have shown a brief example, we will introduce more about
the concepts and design of NIMBLE.  

One of the most important concepts behind NIMBLE is to allow a
combination of high-level processing in R and low-level processing in
C++.  For example, when we write a Metropolis-Hastings MCMC sampler in
the NIMBLE language, the inspection of the model structure related to
one node is done in R, and the actual sampler calculations are done in
C++.  This separation between *setup* and *run* steps
will become clearer as we go.


## NIMBLE adopts and extends the BUGS language for specifying models

We adopted the BUGS language, and we have extended it to make it more
flexible. The BUGS language became widely used in WinBUGS, then in
OpenBUGS and JAGS.  These systems all provide automatically-generated
MCMC algorithms, but we have adopted only the language for describing
models, not their systems for generating MCMCs.  

NIMBLE extends BUGS by:

  * allowing you to write new functions and
distributions and use them in BUGS models;
  * allowing you to define multiple models in the same code using
  conditionals evaluated when the BUGS code is processed;
  * supporting a variety of more flexible syntax such as R-like
  named parameters and more general algebraic expressions.

By supporting new functions and distributions, NIMBLE makes BUGS an
extensible language, which is a major departure from previous
packages that implement BUGS.  

We adopted BUGS because it has been so successful, with over 30,000
users by the time they stopped counting
[@Lunn_Spiegelhalter_Thomas_Best_2009].  Many papers and books
provide BUGS code as a way to document their statistical models. We
describe NIMBLE's version of BUGS later.  The web sites for WinBUGS,
OpenBUGS and JAGS provide other useful documntation on writing models
in BUGS.  For the most part, if you have BUGS code, you can try
NIMBLE.

NIMBLE does several things with BUGS code:

  * NIMBLE creates a *model definition* object that knows
  everything about the variables and their relationships written in
  the BUGS code.  Usually you'll ignore the *model definition*
  and let NIMBLE's default options take you directly to the next step.
  * NIMBLE creates a model object^[or multiple model
    objects].  This can be used to
  manipulate variables and operate the model from R.  Operating the
  model includes calculating, simulating, or querying the log
  probability value of model nodes. These basic capabilities, along
  with the tools to query model structure, allow one to write
  programs that use the model and adapt to its structure.
  * When you're ready, NIMBLE can generate customized C++ code
  representing the model, compile the C++, load it back into R, and
  provide a new model object that uses the compiled model
  internally.  We use the word 'compile' to refer to all of these
  steps together.


As an example of how radical a departure NIMBLE is from previous BUGS
implementations, consider a situation where you want to simulate new
data from a model written in BUGS code.  Since NIMBLE creates model
objects that you can control from R, simulating new data is trivial.
With previous BUGS-based packages, this isn't possible.

More information about specifying and manipulating models is in
Chapters \@ref(cha:building-models) and \@ref(cha:using-bugs-models).

## nimbleFunctions for writing algorithms {#sec:nimble-lang-writ}

NIMBLE provides *nimbleFunction*s for writing functions that can
(but don't have to) use BUGS models.  The main ways that nimbleFunctions can use
BUGS models are:


  * inspecting the structure of a model, such as determining the
  dependencies between variables, in order to do the right
  calculations with each model;
  * accessing values of the model's variables;
  * controlling execution of the model's probability calculations
  or corresponding simulations;
  * managing *modelValues* data structures for multiple sets of
  model values and probabilities.


In fact, the calculations of the model are themselves constructed as
nimbleFunctions, as are the algorithms provided in
NIMBLE's algorithm library^[That's why it's easy to use new
  functions and distributions written as nimbleFunctions in BUGS code.].

Programming with nimbleFunctions involves a fundamental distinction
between two stages of processing:


  * A *setup* function within a nimbleFunction gives the steps
  that need to happen only once for each new situation (e.g., for each
  new model).  Typically such steps include inspecting the model's
  variables and their relationships, such as determining which parts
  of a model will need to be calculated for a MCMC sampler. Setup
  functions are executed in R and never compiled.

  * One or more *run* functions within a nimbleFunction give
  steps that need to happen multiple times using the results of the
  setup function, such as the iterations of a MCMC sampler.
  Formally, run code is written in the NIMBLE language, which you
  can think of as a small subset of R along with features for
  operating models and related data structures.  The NIMBLE language
  is what the NIMBLE compiler can automatically turn into C++ as part
  of a compiled nimbleFunction.


What NIMBLE does with a nimbleFunction is similar to what it does
with a BUGS model:

  * NIMBLE creates a working R version of the nimbleFunction.
  This is most useful for debugging (Section \@ref(sec:debugging)).
  * When you are ready, NIMBLE can generate C++ code, compile it,
  load it back into R and give you new objects that use the compiled
  C++ internally.  Again, we refer to these steps all together as 'compilation.'  The behavior of compiled nimbleFunctions is
  usually very similar, but not identical, to their uncompiled
  counterparts.


If you are familiar with object-oriented programming, you can think of
a nimbleFunction as a class definition. The setup function
initializes a new object and run functions are class methods.
Member data are determined automatically as the objects from a
setup function needed in run functions.  If no setup
function is provided, the nimbleFunction corresponds to a simple
(compilable) function rather than a class.

More about writing algorithms is in Chapter \@ref(cha:progr-with-models).

## The NIMBLE algorithm library {#sec:nimble-algor-libr}

In Version `r version`, the NIMBLE algorithm library includes:


  * MCMC with samplers including conjugate (Gibbs), slice, adaptive
  random walk (with options for reflection or sampling on a log
  scale), adaptive block random walk, and elliptical slice, among others. You can
  modify sampler choices and configurations from R before compiling
  the MCMC.  You can also write new samplers as nimbleFunctions.
  * WAIC calculation for model comparison after an MCMC algorithm has been run.
  * A set of particle filter (sequential Monte Carlo) methods
  including a basic bootstrap filter, auxiliary particle filter, and
  Liu-West filter.
  * An ascent-based Monte Carlo Expectation Maximization (MCEM)
  algorithm.
  * A variety of basic functions that can be used as programming
  tools for larger algorithms.  These include:
  
    * A likelihood function for arbitrary parts of any model.
    * Functions to simulate one or many sets of values for arbitrary
    parts of any model.
    * Functions to calculate the summed log probability (density)
    for one or many sets of values for arbitrary parts of any model
    along with stochastic dependencies in the model structure.
  


<!---  Someone (Perry?) added this comment: Add references where appropriate. Chris suggests we probably don't need refs here as we are referring to very widely-known algorithms. --> 
More about the NIMBLE algorithm library is in Chapter \@ref(cha:algos-provided).

<!--chapter:end:chapter_MoreIntroduction.Rmd-->

<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->


# Installing NIMBLE {#cha:installing-nimble}

## Requirements to run NIMBLE {#sec:requ-run-nimble}

You can run NIMBLE on any of the three common operating systems: Linux, Mac OS X, or Windows. 

The following are required to run NIMBLE.


  * [R](http://www.cran.r-project.org), of course.
  * The [igraph](http://www.cran.r-project.org/web/packages/igraph/index.html) and  [coda](http://www.cran.r-project.org/web/packages/coda/index.html) R packages.
  * A working C++ compiler that NIMBLE can use from R on your system.  There are
  standard open-source C++ compilers that the R community has already
  made easy to install.  See Section \@ref(sec:compiler) for
  instructions.  You don't need to know anything about C++ to use
  NIMBLE.  This must be done before installing NIMBLE.



NIMBLE also uses a couple of C++ libraries that you don't need to install, as they will already be on your system or are provided by NIMBLE.

  * The [Eigen](http://eigen.tuxfamily.org) C++ library
  for linear algebra.  This comes with NIMBLE, or you can use your own copy.
  * The BLAS and LAPACK numerical libraries.  These come with
  R, but see Section \@ref(sec:blas) for how to use a faster version of the BLAS.


Most fairly recent versions of these requirements should work. 
<!---  [look into giving more detailed version requirements] -->

## Installing a C++ compiler for NIMBLE to use {#sec:compiler}

NIMBLE needs a C++ compiler and the standard utility *make* in
order to generate and compile C++ for models and algorithms.^[This differs from most packages, which might need a C++ compiler
  only when the package is built.  If you normally install R packages using
  `install.packages` on Windows or OS X, the package arrives
  already built to your system.]

### OS X
On OS X, you should install *Xcode*.  The command-line tools, which are
available as a smaller installation, should be sufficient. This is freely available from the
[Apple developer
  site](https://developer.apple.com/xcode/downloads/) and the
[App Store](https://itunes.apple.com/us/app/xcode/id497799835?ls=1&mt=12).
<!---  Perry asked if App Store link is stable - Chris checked and it seems fine for now (and is the top hit on a Google search ... -->
For the compiler to work correctly for OS X, the installed R must be
for the correct version of OS X.  For example, R for Snow Leopard (OS
X version 10.8) will attempt to use an incorrect C++ compiler if the
installed OS X is actually version 10.9 or higher.
<!---  PdV -- rewrote this -- need to check example. -->
In the somewhat unlikely event you want to install from the source package rather than the CRAN binary package, the easiest approach is to use the source package provided at [R-nimble.org](http://R-nimble.org). If you do want to install from the source package provided by CRAN, you'll need to install [this gfortran package](http://r.research.att.com/libs/gfortran-4.8.2-darwin13.tar.bz2).

### Linux
On Linux, you can install the GNU compiler suite (*gcc*/*g++*). 
You can use the package manager to install pre-built binaries.
On Ubuntu, the following command will install or update *make*, *gcc* and *libc*.
```{r, chunk1, engine='bash', eval=FALSE}
sudo apt-get install build-essential
``` 

### Windows
On Windows, you should download and install `Rtools.exe`
available from [http://cran.r-project.org/bin/windows/Rtools/].
Select the appropriate executable corresponding to your version of R
(and follow the urge to update your version of R if you notice it
is not the most recent).  This installer leads you through several
'pages'.  We think you can accept the defaults with one exception:
check the PATH checkbox (page 5) so that the installer will add the
location of the C++ compiler and related tools to your system's PATH,
ensuring that R can find them.  After you click 'Next', you will get
a page with a window for customizing the new PATH variable.  You
shouldn't need to do anything there, so you can simply click 'Next'
again.

The checkbox for the 'R 2.15+ toolchain' (page 4) must be checked
(in order to have *gcc*/*g++*, *make*, etc. installed).  This
should be checked by default.

## Installing the NIMBLE package

Since NIMBLE is an R package, you can install it in the usual way, via

`install.packages("nimble")` in R or using the `R CMD INSTALL`
method if you download the package source directly. 

NIMBLE can also be obtained from the [NIMBLE website](http://r-nimble.org). To install from our website, please see our [Download page](http://r-nimble.org/download) for the specific invocation of `install.packages`.


### Problems with installation
We have tested the installation on the three commonly used platforms
-- OS X, Linux, Windows^[We've tested NIMBLE on Windows 7, 8
  and 10.].  We don't anticipate problems with installation,
but we want to hear about any and help resolve them. 
Please post about installation problems to the [nimble-users Google group](https://groups.google.com/forum/#!forum/nimble-users) or 
email [nimble.stats@gmail.com](mailto:nimble.stats@gmail.com).

## Customizing your installation

For most installations, you can ignore low-level details.
However, there are some options that some users may want to utilize.

### Using your own copy of Eigen
<!--- ### Finding the Eigen Header Files -->NIMBLE uses the Eigen C++ template library for linear algebra.  Version 3.2.1
of Eigen is included in the NIMBLE package and that version will be
used unless the package's configuration script finds another version
on the machine.  This works well, and the following is only relevant
if you want to use a different (e.g., newer) version.

The configuration script looks in the standard include directories,
e.g. `/usr/include` and `/usr/local/include` for the header file `Eigen/Dense`.
You can specify a particular location in either of two ways:

    * Set the environment variable `EIGEN_DIR` before installing the R
    package,  e.g., `export EIGEN_DIR=/usr/include/eigen3` in the bash shell.
    * Use 

    `R CMD INSTALL --configure-args='--with-eigen=/path/to/eigen' \` 

    `nimble_VERSION.tar.gz` 

      or 
 `install.packages("nimble", configure.args = "--with-eigen=/path/to/eigen")`.
  
In these cases, the directory should be the full path to the directory that
contains the Eigen directory, e.g., `/usr/include/eigen3`. It is not the full path to the Eigen
directory itself, i.e., NOT `/usr/include/eigen3/Eigen`.


### Using libnimble
NIMBLE generates specialized C++ code for user-specified models and nimbleFunctions.
This code uses some NIMBLE C++ library classes and functions.
By default, on Linux the library code is compiled once as a linkable
library - *libnimble.so*. This single instance of the library is then linked 
with the code for each generated model. In contrast, the default for Windows and Mac OS X
is to compile the library code as a static library - *libnimble.a* - that is compiled into each model's and each algorithm's own dynamically loadable library (DLL). This does repeat the same code across models and so occupies more memory. There may be a marginal speed advantage. 
If one would like to enable the linkable library in place of the static library (do this only on Mac OS X and other UNIX variants and not on Windows), one can install the source package with the configuration argument `--enable-dylib` set to true. First obtain the NIMBLE source package (which will have the extension `.tar.gz` from [our website](http://r-nimble.org/download) and then install as follows, replacing `VERSION` with the appropriate version number:

`R CMD INSTALL --configure-args='--enable-dylib=true' nimble_VERSION.tar.gz`

### BLAS and LAPACK {#sec:blas}

NIMBLE also uses BLAS and LAPACK for some of its linear algebra (in
particular calculating density values and generating random samples
from multivariate distributions). NIMBLE will use the same BLAS and
LAPACK installed on your system that R uses. Note that a fast (and
where appropriate, threaded) BLAS can greatly increase the speed of
linear algebra calculations. See Section A.3.1 of the [R Installation and Administration manual](https://cran.r-project.org/doc/manuals/r-release/R-admin.html) available on CRAN for more details on providing a fast BLAS for your R installation. 

### Customizing compilation of the NIMBLE-generated C++

For each model or nimbleFunction, NIMBLE can generate and compile C++.
To compile generated C++, NIMBLE makes system calls starting with
`R CMD SHLIB` and therefore uses the regular R configuration in
`${R_HOME}/etc/${R_ARCH}/Makeconf`. NIMBLE places a
`Makevars` file in the directory in which the code is generated,
and `R CMD SHLIB` uses this file as usual.

In all but specialized cases, the general compilation mechanism will
suffice. However, one can customize this.  One can specify the
location of an alternative `Makevars` (or `Makevars.win`)
file to use.  Such an alternative file should define the variables `PKG_CPPFLAGS` and
`PKG_LIBS`.  These should contain, respectively, the pre-processor flag
to locate the NIMBLE include directory, and the necessary
libraries to link against (and their location as necessary),
e.g., *Rlapack* and *Rblas* on Windows, and *libnimble*.
Advanced users can also change their default compilers by editing the
*Makevars* file, see Section 1.2.1 of the [Writing R Extensions manual](https://cran.r-project.org/doc/manuals/r-release/R-exts.html) available on CRAN.


Use of this file allows users to specify additional compilation and
linking flags.  See the Writing R Extensions manual for more details
of how this can be used and what it can contain.

<!--chapter:end:chapter_InstallingNimble.Rmd-->

<!--- % See http://yihui.name/knitr/demo/child/ for documentation on the parent/child document system of knitr -->


```{r, echo=FALSE}
require(nimble)
``` 

# Writing models in NIMBLE's dialect of BUGS {#cha:writing-models}

Models in NIMBLE are written using a variation on the BUGS language.
From BUGS code, NIMBLE  creates a model object.  This chapter
describes NIMBLE's version of BUGS.  The next chapter explains how to
build and manipulate model objects.
<!---  With NIMBLE you can also define your own distributions and functions for use in BUGS code; discussion of this functionality is deferred to Chapter \@ref(cha:user-defined) as it requires the use of nimbleFunctions.  -->

## Comparison to BUGS dialects supported by WinBUGS, OpenBUGS and JAGS {#sec:supp-feat-bugs}

Many users will come to NIMBLE with some familiarity with WinBUGS,
OpenBUGS, or JAGS, so we start by summarizing how NIMBLE is similar to
and different from those before documenting NIMBLE's version of BUGS
more completely.  In general, NIMBLE aims to be compatible with the
original BUGS language and also JAGS' version.  However, at this
point, there are some features not supported by NIMBLE, and there are
some extensions that are planned but not implemented.

### Supported features of BUGS and JAGS


  * Stochastic and deterministic^[NIMBLE calls non-stochastic nodes 'deterministic', whereas BUGS calls them 'logical'. NIMBLE uses 'logical' in the way R does, to refer to boolean (TRUE/FALSE) variables.] node declarations.
  * Most univariate and multivariate distributions.
  * Link functions.
  * Most mathematical functions.
  * 'for' loops for iterative declarations.
  * Arrays of nodes up to 4 dimensions.
  * Truncation and censoring as in JAGS using the `T()`
  notation and `dinterval`.


### NIMBLE's Extensions to BUGS and JAGS {#sec:extensions-bugs}

NIMBLE extends the BUGS language in the following ways:


    * User-defined functions and distributions -- written as nimbleFunctions -- can be used in model code. See Chapter \@ref(cha:user-defined).
  * Multiple parameterizations for distributions, similar to those  in R, can be used.
  * Named parameters for distributions and functions, similar to R function calls, can be used.
  * Linear algebra, including for vectorized
  calculations of simple algebra, can be used in deterministic declarations.
  * Distribution parameters can be expressions, as in JAGS but not
  in WinBUGS.  Caveat: parameters to *multivariate*
  distributions (e.g., `dmnorm`) cannot be expressions (but an expression can be defined in a separate deterministic expression and the resulting variable then used). % still true. -Perry
   * Alternative models can be defined from the same model code by
   using if-then-else statements that are evaluated when the model is defined.
  * More flexible indexing of vector nodes within larger variables is allowed.  For example one can place a multivariate normal vector arbitrarily within a higher-dimensional object, not just in the last index.
  * More general constraints can be declared using `dconstraint`, which extends the concept of JAGS' `dinterval`.
   * Link functions can be used in stochastic, as well as
   deterministic, declarations.^[But beware of the possibility
     of needing to set values for 'lifted' nodes created by NIMBLE.]
   * Data values can be reset, and which parts of a model are flagged as data can be changed, allowing one model to be used for different data sets without rebuilding the model each time.
     * As of Version 0.6-6 we now support stochastic/dynamic indexes. More specifically in earlier versions all indexes needed to be constants. Now indexes can be other nodes or functions of other nodes. For a given dimension of a node being indexed, if the index is not constant, it must be a scalar value. So expressions such as `mu[k[i], 3]` or `mu[k[i], 1:3]` or `mu[k[i], j[i]]` are allowed, but not `mu[k[i]:(k[i]+1)]`. Nested dynamic indexes such as `mu[k[j[i]]]` are also allowed. 
  
  
### Not-yet-supported features of BUGS and JAGS {#sec:not-yet-supported}

In this release, the following are not supported.


  * The appearance of the same node on the left-hand side of both a
  `<-` and a `$\sim$` declaration (used in WinBUGS for data
  assignment for the value of a stochastic node).
  * Multivariate nodes must appear with brackets, even if they are
    empty. E.g., `x` cannot be multivariate but `x[]` or
    `x[2:5]` can be.
  * NIMBLE generally determines the dimensionality and
  sizes of variables from the BUGS code.  However, when a variable
  appears with blank indices, such as in `x.sum <- sum(x[])`,
  and if the dimensions of the variable are not clearly defined in
  other declarations, NIMBLE currently requires that the dimensions of
  x be provided when the model object is created (via `nimbleModel`).


## Writing models

Here we introduce NIMBLE's version of BUGS.  The WinBUGS, OpenBUGS and
JAGS manuals are also useful resources for writing BUGS models,
including many examples.

### Declaring stochastic and deterministic nodes

BUGS is a declarative language for graphical (or hierarchical) models.
Most programming languages are imperative, which means a series of
commands will be executed in the order they are written.  A
declarative language like BUGS is more like building a machine before
using it.  Each line declares that a component should be plugged into
the machine, but it doesn't matter in what order they are declared as
long as all the right components are plugged in by the end of the code.

The machine in this case is a graphical model^[Technically, a
  *directed acyclic graph*].  A *node* (sometimes called
a *vertex*) holds one value, which may be a scalar or a vector.
*Edges* define the relationships between nodes.  A huge variety
of statistical models can be thought of as graphs.  

Here is the code to define and create a simple linear regression model with four observations. 

```{r, chunk-WMinit, echo = FALSE}
## source the code
read_chunk(file.path('chunks', 'writingModels_chunks.R'))  # one can put code chunks here if one wants
``` 

```{r, linearRegressionGraph, fig.height=10, fig.width=20, fig.cap="Graph of a linear regression model"}
``` 

The graph representing the model is 
shown in Figure \@ref(fig:linearRegressionGraph).  Each observation,
`y[i]`, is a node whose edges say that it follows a normal
distribution depending on a predicted value, `predicted.y[i]`, and
standard deviation, `sigma`, which are each nodes.  Each predicted
value is a node whose edges say how it is calculated from `slope`,
`intercept`, and one value of an explanatory variable, `x[i]`,
which are each nodes.

This graph is created from the following BUGS code:

```{r, linearRegressionCode, eval=FALSE}
``` 

In this code, stochastic relationships are declared with '$\sim$'
and deterministic relationships are declared with '`<-`'.  For
example, each `y[i]` follows a normal distribution with mean
`predicted.y[i]` and standard deviation
`sigma`.  Each
`predicted.y[i]` is the result of `intercept + slope * x[i]`.
The for-loop yields the equivalent of writing four lines of code, each
with a different value of `i`.  It does not matter in what order
the nodes are declared.  Imagine that each line of code draws part of
Figure \@ref(fig:linearRegressionGraph), and all that matters is that
the everything gets drawn in the end.  Available distributions, default and alternative
  parameterizations, and functions are listed in Section \@ref(subsec:dists-and-functions).

An equivalent graph can be created by this BUGS code:

```{r, linearRegressionAltCode, eval=FALSE}
``` 

In this case, the `predicted.y[i]` nodes in Figure
\@ref(fig:linearRegressionGraph) will be created automatically by
NIMBLE and will have a different name, generated by NIMBLE.

### More kinds of BUGS declarations {#sec:more-kinds-bugs}

Here are some examples of valid lines of BUGS code.  This code does
not describe a sensible or complete model, and it includes some
arbitrary indices (e.g. `mvx[8:10, i]`) to illustrate flexibility.
Instead the purpose of each line is to illustrate a feature of
NIMBLE's version of BUGS.

```{r, didacticnimbleCode, eval=FALSE}
{
    ## 1. normal distribution with BUGS parameter order
    x ~ dnorm(a + b * c, tau) 
    ## 2. normal distribution with a named parameter
    y ~ dnorm(a + b * c, sd = sigma) 
    ## 3. For-loop and nested indexing
    for(i in 1:N) {
        for(j in 1:M[i]) {
            z[i,j] ~ dexp(r[ blockID[i] ]) 
        }
    }
    ## 4. multivariate distribution with arbitrary indexing
    for(i in 1:3) 
        mvx[8:10, i] ~ dmnorm(mvMean[3:5], cov = mvCov[1:3, 1:3, i])
    ## 5. User-provided distribution
    w ~ dMyDistribution(hello = x, world = y) 
    ## 6. Simple deterministic node
    d1 <- a + b
    ## 7. Vector deterministic node with matrix multiplication
    d2[] <- A[ , ] %*% mvMean[1:5] 
    ## 8. Deterministic node with user-provided function
    d3 <- foo(x, hooray = y) 
}
``` 

When a variable appears only on the right-hand side, it can be provided via `constants` (in which case it can never be changed) or via `data` or `inits`, as discussed in Chapter \@ref(cha:building-models).  

Notes on the comment-numbered lines are:


  * `x` follows a normal distribution with mean `a + b*c` and precision `tau` (default BUGS second parameter for `dnorm`).
  * `y` follows a normal distribution with the same mean as `x` but a named standard deviation parameter instead of a precision parameter (sd = 1/sqrt(precision)).
  * `z[i, j]` follows an exponential distribution with parameter
  `r[ blockID[i] ]`.  This shows how for-loops can be used for indexing of variables containing
  multiple nodes.  Variables that define for-loop indices (`N` and `M`) must also be provided as constants.  
  * The arbitrary block `mvx[8:10, i]` follows a multivariate
  normal distribution, with a named covariance matrix instead of BUGS'
  default of a precision matrix.  As in R, curly braces for for-loop
  contents are only needed if there is more than one line.
  * `w` follows a user-defined distribution. See Chapter \@ref(cha:user-defined).
  * `d1` is a scalar deterministic node that, when calculated, will be
  set to `a + b`.
  * `d2` is a vector deterministic node using matrix
  multiplication in R's syntax.
  * `d3` is a deterministic node using a user-provided
  function.  See Chapter \@ref(cha:user-defined).


#### More about indexing {#sec:indexing} 

Examples of allowed indexing include:

  * `x[i]`             \# a single index
  * `x[i:j]`         \# a range of indices
  * `x[i:j,k:l]` \# multiple single indices or ranges for higher-dimensional arrays
  * `x[i:j, ]`     \# blank indices indicating the full range
  * `x[3*i+7]`     \# computed indices
  * `x[(3*i):(5*i+1)]`  \# computed lower and upper ends of an index range
  * `x[k[i]+1]`             \# a dynamic (and computed) index
  * `x[k[j[i]]]`         \# nested dynamic indexes
  * `x[k[i], 1:3]`     \# nested indexing of rows or columns
  
 
NIMBLE does not allow multivariate nodes to be used without
square brackets, which is an incompatibility with JAGS.  Therefore a statement like `xbar <- mean(x)` in JAGS must be converted to
`xbar <- mean(x[])` (if `x` is a vector) or `xbar <-
 mean(x[,])` (if `x` is a matrix) for NIMBLE^[In `nimbleFunctions`
  explained in later chapters, square brackets with blank indices are
  not necessary for multivariate objects.]. Section \@ref(sec:prov-dimens-via) discusses how to provide NIMBLE with dimensions of `x` when needed.

Generally NIMBLE supports R-like linear algebra expressions and attempts to follow the same rules as R about
dimensions (although in some cases this is not possible).  For
example, `x[1:3] \%*\% y[1:3]` converts `x[1:3]` into a row
vector and thus computes the inner product, which is returned as a $1
\times 1$ matrix (use `inprod` to get it as a scalar, which it typically easier).  Like in R,
a scalar index will result in dropping a dimension unless the argument
`drop=FALSE` is provided.  For example, `mymatrix[i, 1:3]` will
be a vector of length 3, but `mymatrix[i, 1:3, drop=FALSE]` will be
a $1 \times 3$ matrix.  More about indexing and dimensions is
discussed in Section \@ref(sec:manag-dimens-sizes).

### Vectorized versus scalar declarations {#subsec:vectorized-versus-scalar-declarations}

Suppose you need nodes `logY[i]` that should be the log of the
corresponding `Y[i]`, say for `i` from 1 to 10.  Conventionally
this would be created with a for loop:
```{r, simpleForLoop, eval=FALSE}
{
    for(i in 1:10) {
        logY[i] <- log(Y[i])
    }
}
``` 

Since NIMBLE supports R-like algebraic expressions, an alternative in
NIMBLE's dialect of BUGS is to use a vectorized declaration like this:
```{r, simpleVecDec, eval=FALSE}
{
    logY[1:10] <- log(Y[1:10])
}
``` 


There is an important difference between the models that are created by the
above two methods.  The first creates 10 scalar nodes, `logY[1]`
$,\ldots,$ `logY[10]`.  The second creates one vector node,
`logY[1:10]`.  If each `logY[i]` is used separately by an algorithm, it may be more efficient computationally if they are declared as scalars.  If they are all used together,
it will often make sense to declare them as a vector.


### Available distributions {#subsec:dists-and-functions}
#### Distributions {#subsec:distributions}

NIMBLE supports most of the distributions allowed in BUGS and
JAGS. Table \@ref(table:distributions) lists the distributions that are
currently supported, with their default parameterizations, which match
those of BUGS^[Note that the same distributions are available
  for writing `nimbleFunction`s, but in that case the default
  parameterizations and function names match R's when possible. Please
  see Section \@ref(sec:nimble-dist-funs) for how to use distributions
  in `nimbleFunctions`.]. NIMBLE also allows one to use alternative
parameterizations for a variety of distributions as described next.
See Section \@ref(sec:user-distributions) to learn how to write new distributions using nimbleFunctions.

```{r, child = 'densityTableLong.md'}
```


##### Improper distributions

Note that `dcar_normal`, `dflat` and `dhalfflat` specify improper prior distributions
and should only be used when the posterior distribution of the model is known to be proper.
Also for these distributions, the density function returns the unnormalized density
and the simulation function returns `NaN` so these distributions
are not appropriate for algorithms that need to simulate from the
prior or require proper (normalized) densities.

#### Alternative parameterizations for distributions {#subsec:alternative-params}

NIMBLE allows one to specify distributions in model code using a
variety of parameterizations, including the BUGS
parameterizations. Available parameterizations are listed in Table \@ref(table:distributions-alternates).
To understand how NIMBLE handles alternative parameterizations, it is
useful to distinguish three cases, using the `gamma` distribution
as an example:

  * A *canonical* parameterization is used directly for
  computations^[Usually this is the parameterization in the
  `Rmath` header of R's C implementation of distributions.].  For
  `gamma`, this is (shape, scale).  
  * The BUGS parameterization is the one defined in the
  original BUGS language. In general this is the parameterization for which conjugate MCMC samplers can be executed most efficiently. For `gamma`, this is (shape, rate). 
  * An *alternative* parameterization is one that must be
  converted into the *canonical* parameterization.  For `gamma`,
  NIMBLE provides both (shape, rate) and (mean, sd) parameterization
  and creates nodes to calculate (shape, scale) from either (shape,
  rate) or (mean, sd).  In the case of `gamma`, the BUGS
  parameterization is also an *alternative* parameterization.



Since NIMBLE provides compatibility with existing BUGS and JAGS
code, the order of parameters places the BUGS parameterization
first.  For example, the order of parameters for `dgamma` is `dgamma(shape, rate, scale, mean, sd)`.  Like R, if
parameter names are not given, they are taken in order, so that (shape,
rate) is the default. This happens to  match R's order of parameters,
but it need not.  If names are given, they can be given in any
order.  NIMBLE knows that rate is an alternative to scale and that
(mean, sd) are an alternative to (shape, scale or rate). 

```{r, child = 'parameterizationTableLong.md'}
```

Note that for multivariate normal, multivariate t, Wishart, and Inverse Wishart, the canonical
parameterization uses the Cholesky decomposition of one of the
precision/inverse scale or covariance/scale matrix. For example, for the multivariate normal, if  `prec_param=TRUE`, the `cholesky` argument is treated as the Cholesky
decomposition of a precision matrix.  Otherwise it is treated as the
Cholesky decomposition of a covariance matrix. 
<!---  In some cases it may be more efficient to use that parameterization -->% directly.  % PdV removed this because it is obtuse: In what cases?
<!---  Doesn't lifting of the cholesky computation take care of inefficiency? -->% What does "use that parameterization directly" mean, when there is
<!---  no meaning of "indirect" use of a parameterization?   -->
In addition, NIMBLE supports alternative distribution names, known as aliases, as in JAGS, as specified in Table \@ref(table:distributions-aliases). 


```{r, child = 'densityAliasesTable.md'}
```


<!--- TODO: WHAT IS THE STATUS OF THE NEXT STATEMENT?: I've added inverse gamma in 0.6-4 and will do inverse wishart in 0.6-5. Hopefully will get to some others as well soon-ish - CJP. -->
We plan to, but do not currently, include the following distributions as part of core NIMBLE: double exponential (Laplace), beta-binomial, Dirichlet-multinomial, F, Pareto, or forms of the multivariate t other than the standard one provided. 
<!---  [F is easy to add as it has R functions] -->


### Available BUGS language functions {#subsec:BUGS-lang-fxns}

Tables \@ref(table:functions-bugs)-\@ref(table:functions-matrix-bugs) show the
available operators and functions. 
<!---  These are also available for `nimbleFunction` programming (see Chapter \@ref(cha:progr-with-models)).  In fact, BUGS model nodes are implemented as `nimbleFunction`s that are custom-generated from BUGS declarations, so it would be more correct to say that functions and operators available for `nimbleFunction`s are also available for the model declarations. -->Support for more general R expressions
is covered in Chapter \@ref(cha:RCfunctions) about programming
with nimbleFunctions. 

For the most part NIMBLE supports the functions used in BUGS and JAGS,
with exceptions indicated in the table.  Additional functions provided
by NIMBLE are also listed. Note that we provide distribution functions
for use in calculations, namely the 'p', 'q', and 'd' functions.
 See Section \@ref(sec:nimble-dist-funs) for details on the syntax for using distribution functions as functions in deterministic calculations, as only some parameterizations are allowed and the names of some distributions differ from those used to define stochastic nodes in a model. 

```{r, child = 'functionTableLong.md'}
```


```{r, child = 'functionTableMatrixLong.md'}
```
```{r, child = 'eigenSvdTableMatrixElements.md'}
```


<!---  [NOTE: JAGS source package has the Tex files for Martyn's manual, so we can copy the table formatting - s doc/manual/jags_user_manual.md] -->
See Section \@ref(sec:user-functions) to learn how to use nimbleFunctions to write new functions for use in BUGS code.

### Available link functions {#subsec:BUGS-link}

NIMBLE allows the link functions listed in Table \@ref(table:links).
<!--- [!h] 
`r version`b+cloglog(y) <- x+ & Complementary log log & $0 < y < 1$ & `r version`b+y <- icloglog(x)+ 

`r version`b+log(y) <- x+    & Log           & $0 < y$ &  `r version`b+y <- exp(x)+ 

`r version`b+logit(y) <- x+  & Logit         & $0 < y < 1$ &  `r version`b+y <- expit(x)+ 

`r version`b+probit(y) <- x+ & Probit        & $0 < y < 1$ &  `r version`b+y <- iprobit(x)+
-->

<!---  -->      
Link functions are specified as functions applied to a node on the
left hand side of a BUGS expression. To handle link functions in
deterministic declarations, NIMBLE converts the declaration into an
equivalent inverse declaration.  For example, `log(y) <- x` is
converted into `y <- exp(x)`.  In other words, the link function is
just a simple variant for conceptual clarity.  

To handle link functions in a stochastic declaration, NIMBLE
does some processing that inserts an additional node into the model.
For example, the declaration `logit(p[i]) $\sim$ dnorm(mu[i],1)`, is equivalent
to the follow two declarations: 

  * `logit_p[i] $\sim$ dnorm(mu[i], 1)`,
  * `p[i] <- expit(logit_p[i])`

where `expit` is the inverse of `logit`.  

Note that NIMBLE does not provide an automatic way of initializing the additional node (`logit_p[i]` in this case), which is a parent node of the explicit node (`p[i]`), without explicitly referring to the additional node by the name that NIMBLE generates. 

### Truncation, censoring, and constraints {#subsec:trunc}

NIMBLE provides three ways to declare boundaries on the value of a variable, each for different situations.  We introduce these and comment on their relationships to related features of JAGS and BUGS.  The three methods are:

#### Truncation
Either of the following forms, 

  * `x $\sim$ dnorm(0, sd = 10) T(0, a)`, or
  * `x $\sim$ T(dnorm(0, sd = 10), 0, a)`, 
  
  declares that `x` follows a normal distribution between 0 and
  `a` (inclusive of 0 and `a`).  Either boundary may be omitted or may be another node, such as `a` in this example.  The first form is compatible with JAGS, but in NIMBLE it can only be used when reading code from a text file.  When writing model code in R, the second version must be used.  

Truncation means the possible values of `x` are limited a priori, hence the probability density of `x` must be normalized^[NIMBLE uses the CDF and inverse CDF (quantile) functions of a distribution to do this; in some cases if one uses truncation to include only the extreme tail of a distribution, numerical difficulties can arise.].  In this example it would be the normal probability density divided by its integral from 0 to `a`.  Like JAGS, NIMBLE also provides `I` as a synonym for `T` to accommodate older BUGS code, but `T` is preferred because it disambiguates multiple usages of `I` in BUGS.

#### Censoring

Censoring refers to the situation where one datum gives the lower or upper bound on an unobserved random variable.  This is common in survival analysis, when for an individual still surviving at the end of a study, the age of death is not known and hence is 'censored' (right-censoring).  NIMBLE adopts JAGS syntax for censoring, as follows (using right-censoring as an example):
 ```{r, dinterval-example, eval=FALSE}
censored[i] ~ dinterval(t[i], c[i])
t[i] ~ dweib(r, mu[i])
```
where `censored[i]` should be given as `data` with a value of 1 if
`t[i]` is right-censored (`t[i] $>$ c[i]`) and 0 if it is
observed.  The data vector for `t` should have `NA` (indicating
missing data) for any censored `t[i]` entries. (As a result, these
nodes will be sampled in an MCMC.)  The data vector for `c` should
give the censoring times corresponding to censored entries and a value
below the observed times for uncensored entries (e.g., `0`, assuming `t[i] $>$ 0`). Left-censoring would be specified by setting `censored[i]` to 0 and `t[i]` to `NA`. 
  

The `dinterval` is not really a distribution but rather a trick: in the above example when `censored[i] = 1` it gives a 'probability' of 1 if `t[i] $>$ c[i]` and 0 otherwise.  This means that `t[i] $\le$ c[i]` is treated as impossible.  More generally than simple right- or left-censoring, `censored[i] $\sim$ dinterval(t[i], c[i, ])` is defined such that for a vector of increasing cutpoints, `c[i, ]`, `t[i]` is enforced to fall within the `censored[i]`-th cutpoint interval.  This is done by setting data `censored[i]` as follows:

\mbox{`censored[i] = 0`} & \mbox{if} & \mbox{`t[i] $\le$ c[i, 1]`} \nonumber 

\mbox{`censored[i] = m`} & \mbox{if} & \mbox{`c[i, m] $<$ t[i] $\le$ c[i, m+1]` for } 1 <= m <= M \nonumber 

\mbox{`censored[i] = M`} & \mbox{if} & \mbox{`c[i, M] $<$ t[i]`}.\nonumber

(The `i` index is provided only for consistency with the previous example.)  The most common uses of `dinterval` will be for left- and right-censored data, in which case `c[i,]` will be a single value (and typically given as simply `c[i]`), and for interval-censored data, in which case `c[i,]` will be a vector of two values.  
<!---  TODO: Next line removed by CJP as I thought it was confusing: -->% or `x[i] $\sim$ dinterval(c[i], t[i])` with `x[i]` set to 1.
<!---  WHY - our dinterval code treats the 2nd arg as possibly a vector - the above presumably works for scalars but I think it is clearer if we always use the first arg as the data value and the 2nd as the interval points -->
Nodes following a `dinterval` distribution should normally be set
as `data` with known values. Otherwise, the node may be simulated during initialization in some algorithms (e.g., MCMC) and thereby establish a permanent, perhaps unintended, constraint.  

Censoring differs from truncation because censoring an observation involves bounds on a random variable that could have taken any value, while in truncation we know a priori that a datum could not have occurred outside the truncation range.  


#### Constraints and ordering

NIMBLE provides a more general way to enforce constraints using `dconstraint(cond)`.  For example, we could specify that the sum of `mu1` and `mu2` must be positive like this:
```{r, dconstraint-example, eval=FALSE}
mu1 ~ dnorm(0, 1) 
mu2 ~ dnorm(0, 1) 
constraint_data ~ dconstraint( mu1 + mu2 > 0 )
``` 
with `constraint_data` set (as `data`) to 1.  This is
equivalent to a half-normal distribution on the half-plane $\mu_1 +
\mu_2 > 0$.  Nodes following `dconstraint` should be provided as data for the same reason of avoiding unintended initialization described above for `dinterval`.
<!--- If one simulates from the model using the `simulate` functions and the condition is not satisfied, then `const` will be 0 and the log probability of `const` (and therefore of the model as whole) will be $-\infty$. -->
Formally, `dconstraint(cond)` is a probability distribution on $\left\{ 0, 1 \right\}$ such that $P(1) = 1$ if `cond` is `TRUE` and $P(0) = 1$ if `cond` is `FALSE`. 
<!---  TODO: Chris thought this wording is confusing: -->%Like `dinterval`, `dconstraint` results in distributions that are not normalized (e.g. for (`mu1`, `mu2`)), which makes most sense if the constraint is observed rather than established a priori. 

Of course, in many cases, parameterizing the model so that the
constraints are automatically respected may be a better strategy than
using `dconstraint`.  One should be cautious about constraints that
would make it hard for an MCMC or optimization to move through the
parameter space (such as equality constraints that involve two or more
parameters). For such restrictive constraints, general purpose
algorithms that are not tailored to the constraints may fail or be inefficient. If constraints are used, it will generally be wise to ensure the model is initialized with values that satisfy them.


##### Ordering

To specify an ordering of parameters, such as $\alpha_1 <= \alpha_2 <= \alpha_3$ one can use `dconstraint` as follows: 
```{r, ordering-example, eval=FALSE}
constraint_data ~ dconstraint( alpha1 <= alpha2 & alpha2 <= alpha3 )
``` 

Note that unlike in BUGS, one cannot specify prior ordering using syntax such as

alpha[1] ~ dnorm(0, 1) I(, alpha[2])
alpha[2] ~ dnorm(0, 1) I(alpha[1], alpha[3])
alpha[3] ~ dnorm(0, 1) I(alpha[2], )

as this does not represent a directed acyclic graph. 
<!---  TODO: CHRIS, WOULDN'T THIS WORK WITH `alpha[1] $\sim$ dnorm(0, 1)`?  DOES BUGS REALLY ALLOW THIS NON-DAG? -->% PERRY, JAGS manual indicates the above is allowed in BUGS. Are you asking if it would work in NIMBLE with alpha1~dnorm(0,1) -- no because alpha2 still depends on alpha3 and vice versa

Also note that specifying prior ordering using `T(,)` can result in possibly unexpected results.  For example:

alpha1 ~ dnorm(0, 1)
alpha2 ~ dnorm(0, 1) T(alpha1, )
alpha3 ~ dnorm(0, 1) T(alpha2, )

will enforce `alpha1 $\le$ alpha2 $\le$ alpha3`, but it does not treat the three parameters symmetrically.  Instead it puts a marginal prior on `alpha1` that is standard normal and then constrains `alpha2` and `alpha3` to follow truncated normal distributions. This is not equivalent to a symmetric prior on the three `alpha`s that assigns zero probability density when values are not in order.

NIMBLE does not support the JAGS `sort` syntax.



<!--chapter:end:chapter_WritingModels.Rmd-->

